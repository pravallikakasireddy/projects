{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv(r\"C:\\Users\\HP\\Desktop\\profeb15\\train.csv\",index_col=\"Store\")\n",
    "#df1 = pd.read_csv(\"../input/retaildataset/sales data-set.csv\",index_col=\"Store\")\n",
    "#stores data_set = pd.read_csv(\"../input/retaildataset/stores data-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df1.loc[\"0\":\"10\"]\n",
    "data.reset_index(level=0, inplace=True)\n",
    "k=list(data.columns)\n",
    "k[-1],k[-2]=k[-2],k[-1]\n",
    "columns_titles = k\n",
    "data=data.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# converting string date into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "data['Date'] = data['Date'].apply(lambda x: (dt.strptime(x,'%Y-%m-%d').date()).toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=[]\n",
    "# test=[]\n",
    "# from datetime import datetime as dt\n",
    "# for i in data.values:\n",
    "#     i[-2],i[-1]=i[-1],i[-2]\n",
    "#     year=(i[2].split('-'))[2]\n",
    "#     d = dt.strptime(i[2], '%Y-%m-%d').date()\n",
    "#     i[2]=d.toordinal()\n",
    "#     if(year==\"2012\"):\n",
    "#         test.append(i)\n",
    "#     else:\n",
    "#         train.append(i)\n",
    "# print(test)\n",
    "\n",
    "# train_data=pd.DataFrame(train,columns=k)\n",
    "# test_data=pd.DataFrame(test,columns=k)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=data.iloc[:,:4]\n",
    "y=data.iloc[:,4:]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953634427022679\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import math\n",
    "score=0\n",
    "final_reg_obj=0\n",
    "ran_estimators=1\n",
    "\n",
    "for i in range(1,300,50):\n",
    "\n",
    "#creating an object for the model\n",
    "    reg_obj=RandomForestRegressor(n_estimators=i,random_state=0)\n",
    "\n",
    "#training the model\n",
    "    reg_obj.fit(train_x,train_y.values.ravel())\n",
    "\n",
    "#predicting \n",
    "    pred_y=reg_obj.predict(test_x)\n",
    "\n",
    "#checking score \n",
    "    pred_score=r2_score(test_y,pred_y)\n",
    "    if(pred_score>score):\n",
    "        final_reg_obj=reg_obj\n",
    "        score=pred_score\n",
    "        rn_estimators=i\n",
    "    else:\n",
    "        del (reg_obj)\n",
    "        \n",
    "print(score)\n",
    "print(rn_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9545540700478137\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import math\n",
    "score=0\n",
    "final_reg_obj=0\n",
    "gb_estimators=1\n",
    "\n",
    "for i in range(1,300,50):\n",
    "\n",
    "#creating an object for the model\n",
    "    reg_obj=GradientBoostingRegressor(n_estimators=i,random_state=0)\n",
    "\n",
    "#training the model\n",
    "    reg_obj.fit(train_x,train_y.values.ravel())\n",
    "\n",
    "#predicting \n",
    "    pred_y=reg_obj.predict(test_x)\n",
    "\n",
    "#checking score \n",
    "    pred_score=(r2_score(test_y,pred_y))\n",
    "    if(pred_score>score):\n",
    "        final_reg_obj=reg_obj\n",
    "        score=pred_score\n",
    "        gb_estimators=i\n",
    "    else:\n",
    "        del (reg_obj)\n",
    "        \n",
    "print(score)\n",
    "print(gb_estimators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:16:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.9551455531544593\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import math\n",
    "score=0\n",
    "final_reg_obj=0\n",
    "xg_estimators=1\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=x,label=y)\n",
    "\n",
    "\n",
    "for i in range(1,300,50):\n",
    "\n",
    "#creating an object for the model\n",
    "    xg_reg = xgb.XGBRegressor(n_estimators=i)\n",
    "\n",
    "#training the model\n",
    "    xg_reg.fit(train_x,train_y.values.ravel())\n",
    "\n",
    "#predicting \n",
    "    pred_y=xg_reg.predict(test_x)\n",
    "\n",
    "#checking score \n",
    "    pred_score=(r2_score(test_y,pred_y))\n",
    "    if(pred_score>score):\n",
    "        final_reg_obj=xg_reg\n",
    "        score=pred_score\n",
    "        xg_estimators=i\n",
    "    else:\n",
    "        del (xg_reg)\n",
    "        \n",
    "print(score)\n",
    "print(xg_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#maintaining a list for all the models\n",
    "models=list()\n",
    "\n",
    "#converting data into matrix\n",
    "data_dmatrix = xgb.DMatrix(data=x,label=y)\n",
    "\n",
    "#creating xgboostregressor object\n",
    "xg_reg = xgb.XGBRegressor(n_estimators=xg_estimators)\n",
    "\n",
    "#creating randomforestregressor object\n",
    "reg_obj=RandomForestRegressor(n_estimators=rn_estimators,random_state=0)\n",
    "\n",
    "#creating gradientboosting regressor object\n",
    "grad_obj=GradientBoostingRegressor(n_estimators=gb_estimators)\n",
    "\n",
    "#appending all objects in the list\n",
    "models.append(xg_reg)\n",
    "models.append(reg_obj)\n",
    "models.append(grad_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error,r2_score\n",
    "# import math\n",
    "# predicted_rows=list()\n",
    "# temp=models\n",
    "\n",
    "# for i in temp:\n",
    "#     i.fit(x_train,y_train.values.ravel())\n",
    "#     out=i.predict(x_test)\n",
    "#     predicted_rows.append(out)\n",
    "#     print(math.sqrt(r2_score(y_test,out)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predicted_rows)\n",
    "# l=predicted_rows\n",
    "# out=[(l[0][i]+l[1][i])/2 for i in range(len(l[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(math.sqrt(r2_score(test_y,out)))\n",
    "# print(train_x)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the models using k splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:16:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:16:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#maintaining a list for level1 predictions\n",
    "level1_x=[[],[],[]]\n",
    "\n",
    "#true values \n",
    "level1_y=[]\n",
    "\n",
    "#for splitting the data into k folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#splitting the data into 5 splits where 1 split is used as test data\n",
    "kf = KFold(n_splits =5 , shuffle = True, random_state = 5)\n",
    "for train_index,test_index in kf.split(train_x):\n",
    "    kf_xtrain,kf_xtest=train_x.iloc[train_index],train_x.iloc[test_index]\n",
    "    kf_ytrain,kf_ytest=train_y.iloc[train_index],train_y.iloc[test_index]\n",
    "    \n",
    "    # train the every model using the same folds\n",
    "    for i in range(len(models)):\n",
    "        models[i].fit(kf_xtrain,kf_ytrain.values.ravel())\n",
    "        \n",
    "        #predicting values for k-1 split\n",
    "        out=models[i].predict(kf_xtest)\n",
    "        \n",
    "        out=list(out)\n",
    "        \n",
    "        #appending the predicted values to the list \n",
    "        level1_x[i].extend(out)\n",
    "    \n",
    "    #appending actual true values  \n",
    "    level1_y.extend(kf_ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transposing the predicted values at level1\n",
    "\n",
    "import numpy as np\n",
    "level1_x=np.array(level1_x)\n",
    "level1_x=level1_x.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize='True')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "#converting the data into datframes\n",
    "level1_train_x=pd.DataFrame(level1_x)\n",
    "level1_train_y=pd.DataFrame(level1_y)\n",
    "\n",
    "#reshaping the label y\n",
    "level1_train_y=level1_train_y.squeeze()\n",
    "\n",
    "#creating ultimate model at level 2\n",
    "ultimate_model = linear_model.LinearRegression(normalize='True')\n",
    "\n",
    "#training the model with level1 predictions\n",
    "ultimate_model.fit(level1_train_x, level1_train_y) \n",
    "\n",
    "##ultimate_model=GradientBoostingRegressor()\n",
    "##ultimate_model.fit(level1_train_x,level1_train_y)\n",
    "## from sklearn.svm import SVR\n",
    "##ultimate_model=SVR(kernel=\"rbf\")\n",
    "##ultimate_model.fit(level1_train_x,level1_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting values using the stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list to get predicted values for all the three models\n",
    "predicted=[[],[],[]]\n",
    "\n",
    "\n",
    "for i in range(len(models)):\n",
    "    #predicting and adding the values to the predicted list\n",
    "    predicted[i].extend(models[i].predict(test_x))\n",
    "\n",
    "#transpose the predicted values to get (n,3) shape\n",
    "predicted=np.array(predicted)\n",
    "predicted=predicted.transpose()\n",
    "\n",
    "#converting into dataframe\n",
    "level1_predict_x=pd.DataFrame(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting values using the level1 predictions as input\n",
    "out_y=ultimate_model.predict(level1_predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9811404885848599\n"
     ]
    }
   ],
   "source": [
    "#r2_score for the predicted values\n",
    "print(math.sqrt(r2_score(test_y,out_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
